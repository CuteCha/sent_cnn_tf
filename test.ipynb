{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import data_helpers\n",
    "import train_cnn\n",
    "from sent_cnn import SentCNN\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_u_i, x_r_i, y, max_len, U = train_cnn.load_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: embedded_u -> Tensor(\"embedding_1/embedding_lookup:0\", shape=(?, 22, 100), dtype=float32)\n",
      "DEBUG: embedded_r -> Tensor(\"embedding_1/embedding_lookup_1:0\", shape=(?, 6, 22, 100), dtype=float32)\n",
      "DEBUG: embedded_u_expanded -> Tensor(\"embedding_1/ExpandDims:0\", shape=(?, 22, 100, 1), dtype=float32)\n",
      "DEBUG: embedded_r_expanded -> Tensor(\"embedding_1/ExpandDims_1:0\", shape=(?, 6, 22, 100, 1), dtype=float32)\n",
      "DEBUG: pooled_outputs_u -> [<tf.Tensor 'conv-maxpool-3-u_1/pool-u:0' shape=(?, 1, 1, 3) dtype=float32>, <tf.Tensor 'conv-maxpool-4-u_1/pool-u:0' shape=(?, 1, 1, 3) dtype=float32>]\n",
      "DEBUG: h_pool_u -> Tensor(\"concat_2:0\", shape=(?, 1, 1, 6), dtype=float32)\n",
      "DEBUG: h_pool_flat_u -> Tensor(\"Reshape_2:0\", shape=(?, 1, 6), dtype=float32)\n",
      "DEBUG: pooled_outputs_r -> [<tf.Tensor 'conv-maxpool-3-u_1/concat:0' shape=(?, 1, 6, 3) dtype=float32>, <tf.Tensor 'conv-maxpool-4-u_1/concat:0' shape=(?, 1, 6, 3) dtype=float32>]\n",
      "DEBUG: h_pool_r -> Tensor(\"concat_3:0\", shape=(?, 1, 6, 6), dtype=float32)\n",
      "DEBUG: h_pool_flat_r -> Tensor(\"Reshape_3:0\", shape=(?, 6, 6), dtype=float32)\n",
      "DEBUG: h_features -> Tensor(\"dropout_1/concat:0\", shape=(?, 7, 6), dtype=float32)\n",
      "DEBUG: dot -> Tensor(\"cosine_layer_1/Sum:0\", shape=(?, 6), dtype=float32)\n",
      "DEBUG: sqrt_u -> Tensor(\"cosine_layer_1/Sqrt:0\", shape=(?, 1), dtype=float32)\n",
      "DEBUG: sqrt_r -> Tensor(\"cosine_layer_1/Sqrt_1:0\", shape=(?, 6), dtype=float32)\n",
      "DEBUG: cosine -> Tensor(\"cosine_layer_1/div:0\", shape=(?, 6), dtype=float32)\n",
      "DEBUG: predictions -> Tensor(\"cosine_layer_1/predictions:0\", shape=(?,), dtype=int64)\n",
      "2016-05-13T07:10:21.281958: step 50, train loss 1.54261, train acc 0.484, dev loss 1.37868, dev acc 0.556\n",
      "2016-05-13T07:10:30.725077: step 100, train loss 1.39591, train acc 0.492, dev loss 1.1053, dev acc 0.638\n",
      "2016-05-13T07:10:40.135850: step 150, train loss 1.19191, train acc 0.57, dev loss 0.901558, dev acc 0.724\n",
      "2016-05-13T07:10:49.557463: step 200, train loss 1.16595, train acc 0.65, dev loss 0.782446, dev acc 0.75\n",
      "2016-05-13T07:10:58.970764: step 250, train loss 1.00213, train acc 0.676, dev loss 0.717386, dev acc 0.76\n",
      "2016-05-13T07:11:08.339824: step 300, train loss 0.853809, train acc 0.704, dev loss 0.658623, dev acc 0.782\n",
      "2016-05-13T07:11:17.774241: step 350, train loss 0.90966, train acc 0.712, dev loss 0.614383, dev acc 0.794\n",
      "2016-05-13T07:11:27.159609: step 400, train loss 0.883171, train acc 0.76, dev loss 0.567616, dev acc 0.814\n",
      "2016-05-13T07:11:36.555282: step 450, train loss 1.00376, train acc 0.734, dev loss 0.538706, dev acc 0.82\n",
      "2016-05-13T07:11:45.940406: step 500, train loss 0.854417, train acc 0.75, dev loss 0.538306, dev acc 0.83\n",
      "2016-05-13T07:11:55.323071: step 550, train loss 0.822883, train acc 0.782, dev loss 0.518533, dev acc 0.822\n",
      "2016-05-13T07:12:04.685899: step 600, train loss 0.825872, train acc 0.778, dev loss 0.497641, dev acc 0.838\n",
      "2016-05-13T07:12:14.071732: step 650, train loss 0.712625, train acc 0.738, dev loss 0.485477, dev acc 0.83\n",
      "2016-05-13T07:12:23.467215: step 700, train loss 0.841269, train acc 0.79, dev loss 0.477191, dev acc 0.842\n",
      "2016-05-13T07:12:32.867132: step 750, train loss 0.710685, train acc 0.782, dev loss 0.472626, dev acc 0.848\n",
      "2016-05-13T07:12:42.242670: step 800, train loss 0.80365, train acc 0.782, dev loss 0.477518, dev acc 0.85\n",
      "2016-05-13T07:12:51.627310: step 850, train loss 0.669002, train acc 0.806, dev loss 0.495782, dev acc 0.838\n",
      "2016-05-13T07:13:01.017753: step 900, train loss 0.652411, train acc 0.8, dev loss 0.481352, dev acc 0.848\n",
      "2016-05-13T07:13:10.406419: step 950, train loss 0.787853, train acc 0.794, dev loss 0.488953, dev acc 0.852\n",
      "2016-05-13T07:13:19.818371: step 1000, train loss 0.627593, train acc 0.81, dev loss 0.479904, dev acc 0.848\n",
      "2016-05-13T07:13:29.197283: step 1050, train loss 0.691391, train acc 0.78, dev loss 0.477678, dev acc 0.86\n",
      "2016-05-13T07:13:38.604754: step 1100, train loss 0.719231, train acc 0.802, dev loss 0.477457, dev acc 0.852\n",
      "2016-05-13T07:13:47.978393: step 1150, train loss 0.48972, train acc 0.836, dev loss 0.493368, dev acc 0.854\n",
      "2016-05-13T07:13:57.357607: step 1200, train loss 0.770182, train acc 0.782, dev loss 0.490508, dev acc 0.858\n",
      "2016-05-13T07:14:06.747392: step 1250, train loss 0.808628, train acc 0.76, dev loss 0.481915, dev acc 0.86\n",
      "2016-05-13T07:14:16.121950: step 1300, train loss 0.883027, train acc 0.784, dev loss 0.482271, dev acc 0.856\n",
      "2016-05-13T07:14:25.499424: step 1350, train loss 0.620999, train acc 0.816, dev loss 0.483784, dev acc 0.852\n",
      "2016-05-13T07:14:34.852807: step 1400, train loss 0.595603, train acc 0.818, dev loss 0.473768, dev acc 0.858\n",
      "2016-05-13T07:14:44.218295: step 1450, train loss 0.647311, train acc 0.84, dev loss 0.482134, dev acc 0.864\n",
      "2016-05-13T07:14:53.597681: step 1500, train loss 0.543812, train acc 0.81, dev loss 0.486695, dev acc 0.85\n",
      "2016-05-13T07:15:03.009894: step 1550, train loss 0.62301, train acc 0.802, dev loss 0.480218, dev acc 0.854\n",
      "2016-05-13T07:15:12.440320: step 1600, train loss 0.783434, train acc 0.792, dev loss 0.489443, dev acc 0.85\n",
      "2016-05-13T07:15:21.807409: step 1650, train loss 0.586878, train acc 0.802, dev loss 0.481726, dev acc 0.862\n",
      "2016-05-13T07:15:31.194706: step 1700, train loss 0.578725, train acc 0.83, dev loss 0.493382, dev acc 0.862\n",
      "2016-05-13T07:15:40.612401: step 1750, train loss 0.554186, train acc 0.808, dev loss 0.479076, dev acc 0.856\n",
      "2016-05-13T07:15:50.037695: step 1800, train loss 0.544351, train acc 0.822, dev loss 0.484151, dev acc 0.85\n",
      "2016-05-13T07:15:59.422692: step 1850, train loss 0.493151, train acc 0.81, dev loss 0.468915, dev acc 0.854\n",
      "2016-05-13T07:16:08.822588: step 1900, train loss 0.702134, train acc 0.786, dev loss 0.461186, dev acc 0.866\n",
      "2016-05-13T07:16:18.170112: step 1950, train loss 0.518003, train acc 0.818, dev loss 0.450257, dev acc 0.864\n",
      "2016-05-13T07:16:27.519090: step 2000, train loss 0.459968, train acc 0.82, dev loss 0.450082, dev acc 0.858\n",
      "2016-05-13T07:16:36.901136: step 2050, train loss 0.593601, train acc 0.826, dev loss 0.444811, dev acc 0.864\n",
      "2016-05-13T07:16:46.308038: step 2100, train loss 0.460643, train acc 0.824, dev loss 0.452276, dev acc 0.868\n",
      "2016-05-13T07:16:55.721692: step 2150, train loss 0.538791, train acc 0.806, dev loss 0.462279, dev acc 0.866\n",
      "2016-05-13T07:17:05.124831: step 2200, train loss 0.540654, train acc 0.8, dev loss 0.448263, dev acc 0.866\n",
      "2016-05-13T07:17:14.499933: step 2250, train loss 0.528006, train acc 0.826, dev loss 0.473411, dev acc 0.866\n",
      "2016-05-13T07:17:23.896398: step 2300, train loss 0.454085, train acc 0.816, dev loss 0.454022, dev acc 0.876\n",
      "2016-05-13T07:17:33.266331: step 2350, train loss 0.557716, train acc 0.83, dev loss 0.442204, dev acc 0.87\n",
      "2016-05-13T07:17:42.654993: step 2400, train loss 0.651162, train acc 0.802, dev loss 0.449488, dev acc 0.872\n",
      "2016-05-13T07:17:52.022937: step 2450, train loss 0.761218, train acc 0.806, dev loss 0.43762, dev acc 0.866\n",
      "2016-05-13T07:18:01.416539: step 2500, train loss 0.575035, train acc 0.794, dev loss 0.462575, dev acc 0.858\n",
      "2016-05-13T07:18:10.786613: step 2550, train loss 0.680394, train acc 0.816, dev loss 0.477549, dev acc 0.866\n",
      "2016-05-13T07:18:20.161814: step 2600, train loss 0.567239, train acc 0.816, dev loss 0.443973, dev acc 0.862\n",
      "2016-05-13T07:18:29.508642: step 2650, train loss 0.540239, train acc 0.82, dev loss 0.440684, dev acc 0.876\n",
      "2016-05-13T07:18:38.879698: step 2700, train loss 0.541041, train acc 0.828, dev loss 0.430705, dev acc 0.878\n",
      "2016-05-13T07:18:48.247003: step 2750, train loss 0.414406, train acc 0.84, dev loss 0.442361, dev acc 0.886\n",
      "2016-05-13T07:18:57.642863: step 2800, train loss 0.524674, train acc 0.786, dev loss 0.458979, dev acc 0.872\n",
      "2016-05-13T07:19:06.993600: step 2850, train loss 0.595642, train acc 0.792, dev loss 0.455634, dev acc 0.88\n",
      "2016-05-13T07:19:16.368542: step 2900, train loss 0.564602, train acc 0.806, dev loss 0.438686, dev acc 0.866\n",
      "2016-05-13T07:19:25.787658: step 2950, train loss 0.408458, train acc 0.87, dev loss 0.438545, dev acc 0.878\n",
      "2016-05-13T07:19:35.200961: step 3000, train loss 0.580272, train acc 0.816, dev loss 0.444511, dev acc 0.878\n",
      "2016-05-13T07:19:44.572820: step 3050, train loss 0.51214, train acc 0.834, dev loss 0.445245, dev acc 0.876\n",
      "2016-05-13T07:19:53.981191: step 3100, train loss 0.470211, train acc 0.838, dev loss 0.44597, dev acc 0.886\n",
      "2016-05-13T07:20:03.305366: step 3150, train loss 0.430913, train acc 0.826, dev loss 0.427916, dev acc 0.884\n",
      "2016-05-13T07:20:12.715734: step 3200, train loss 0.490485, train acc 0.824, dev loss 0.444963, dev acc 0.888\n",
      "2016-05-13T07:20:22.121745: step 3250, train loss 0.507944, train acc 0.82, dev loss 0.434664, dev acc 0.888\n",
      "2016-05-13T07:20:31.585546: step 3300, train loss 0.623347, train acc 0.804, dev loss 0.41757, dev acc 0.876\n",
      "2016-05-13T07:20:40.935785: step 3350, train loss 0.53702, train acc 0.788, dev loss 0.418102, dev acc 0.88\n",
      "2016-05-13T07:20:50.289625: step 3400, train loss 0.485626, train acc 0.836, dev loss 0.43873, dev acc 0.878\n",
      "2016-05-13T07:20:59.692752: step 3450, train loss 0.513665, train acc 0.818, dev loss 0.426295, dev acc 0.868\n",
      "2016-05-13T07:21:09.111733: step 3500, train loss 0.591944, train acc 0.814, dev loss 0.429012, dev acc 0.874\n",
      "2016-05-13T07:21:18.485204: step 3550, train loss 0.493359, train acc 0.824, dev loss 0.463791, dev acc 0.872\n",
      "2016-05-13T07:21:27.872984: step 3600, train loss 0.463495, train acc 0.83, dev loss 0.432325, dev acc 0.884\n",
      "2016-05-13T07:21:37.261847: step 3650, train loss 0.520015, train acc 0.832, dev loss 0.434926, dev acc 0.886\n",
      "2016-05-13T07:21:46.609942: step 3700, train loss 0.409353, train acc 0.854, dev loss 0.436812, dev acc 0.888\n",
      "2016-05-13T07:21:55.995341: step 3750, train loss 0.653256, train acc 0.782, dev loss 0.429773, dev acc 0.87\n",
      "2016-05-13T07:22:05.448714: step 3800, train loss 0.496494, train acc 0.798, dev loss 0.419836, dev acc 0.878\n",
      "2016-05-13T07:22:14.875505: step 3850, train loss 0.474422, train acc 0.782, dev loss 0.425904, dev acc 0.88\n",
      "2016-05-13T07:22:24.216138: step 3900, train loss 0.528762, train acc 0.818, dev loss 0.435092, dev acc 0.886\n",
      "2016-05-13T07:22:33.576437: step 3950, train loss 0.468865, train acc 0.828, dev loss 0.42909, dev acc 0.886\n",
      "2016-05-13T07:22:42.979077: step 4000, train loss 0.528354, train acc 0.824, dev loss 0.444036, dev acc 0.878\n",
      "2016-05-13T07:22:52.366635: step 4050, train loss 0.575087, train acc 0.794, dev loss 0.433103, dev acc 0.888\n",
      "2016-05-13T07:23:01.760731: step 4100, train loss 0.530645, train acc 0.816, dev loss 0.454421, dev acc 0.884\n",
      "2016-05-13T07:23:11.146624: step 4150, train loss 0.406235, train acc 0.848, dev loss 0.475238, dev acc 0.874\n",
      "2016-05-13T07:23:20.552484: step 4200, train loss 0.522952, train acc 0.834, dev loss 0.44852, dev acc 0.882\n",
      "2016-05-13T07:23:29.939431: step 4250, train loss 0.465, train acc 0.826, dev loss 0.437733, dev acc 0.878\n",
      "2016-05-13T07:23:39.344057: step 4300, train loss 0.448606, train acc 0.838, dev loss 0.445997, dev acc 0.878\n",
      "2016-05-13T07:23:48.713403: step 4350, train loss 0.624187, train acc 0.844, dev loss 0.462552, dev acc 0.888\n",
      "2016-05-13T07:23:58.172099: step 4400, train loss 0.397997, train acc 0.856, dev loss 0.466873, dev acc 0.872\n",
      "2016-05-13T07:24:07.603841: step 4450, train loss 0.450714, train acc 0.832, dev loss 0.483753, dev acc 0.88\n",
      "2016-05-13T07:24:16.997429: step 4500, train loss 0.353953, train acc 0.868, dev loss 0.477696, dev acc 0.89\n",
      "2016-05-13T07:24:26.374449: step 4550, train loss 0.478285, train acc 0.816, dev loss 0.481997, dev acc 0.878\n",
      "2016-05-13T07:24:35.790406: step 4600, train loss 0.603123, train acc 0.788, dev loss 0.477334, dev acc 0.874\n",
      "2016-05-13T07:24:45.166998: step 4650, train loss 0.472338, train acc 0.82, dev loss 0.471921, dev acc 0.872\n",
      "2016-05-13T07:24:54.586579: step 4700, train loss 0.537742, train acc 0.824, dev loss 0.50941, dev acc 0.868\n",
      "2016-05-13T07:25:03.983369: step 4750, train loss 0.652756, train acc 0.838, dev loss 0.496285, dev acc 0.88\n",
      "2016-05-13T07:25:13.399475: step 4800, train loss 0.629852, train acc 0.79, dev loss 0.533996, dev acc 0.868\n",
      "2016-05-13T07:25:22.766160: step 4850, train loss 0.388936, train acc 0.834, dev loss 0.524193, dev acc 0.864\n",
      "2016-05-13T07:25:32.137577: step 4900, train loss 0.4137, train acc 0.85, dev loss 0.518166, dev acc 0.862\n",
      "2016-05-13T07:25:41.505305: step 4950, train loss 0.60254, train acc 0.808, dev loss 0.508051, dev acc 0.882\n",
      "2016-05-13T07:25:50.855890: step 5000, train loss 0.532477, train acc 0.81, dev loss 0.528267, dev acc 0.886\n"
     ]
    }
   ],
   "source": [
    "train_cnn.train_cnn(x_u_i, x_r_i, y, max_len, U, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: embedded_u -> Tensor(\"embedding_4/embedding_lookup:0\", shape=(?, 22, 100), dtype=float32)\n",
      "DEBUG: embedded_r -> Tensor(\"embedding_4/embedding_lookup_1:0\", shape=(?, 6, 22, 100), dtype=float32)\n",
      "DEBUG: embedded_u_expanded -> Tensor(\"embedding_4/ExpandDims:0\", shape=(?, 22, 100, 1), dtype=float32)\n",
      "DEBUG: embedded_r_expanded -> Tensor(\"embedding_4/ExpandDims_1:0\", shape=(?, 6, 22, 100, 1), dtype=float32)\n",
      "DEBUG: pooled_outputs_u -> [<tf.Tensor 'conv-maxpool-3-u_4/pool-u:0' shape=(?, 1, 1, 3) dtype=float32>, <tf.Tensor 'conv-maxpool-4-u_4/pool-u:0' shape=(?, 1, 1, 3) dtype=float32>]\n",
      "DEBUG: h_pool_u -> Tensor(\"concat_8:0\", shape=(?, 1, 1, 6), dtype=float32)\n",
      "DEBUG: h_pool_flat_u -> Tensor(\"Reshape_8:0\", shape=(?, 1, 6), dtype=float32)\n",
      "DEBUG: pooled_outputs_r -> [<tf.Tensor 'conv-maxpool-3-u_4/concat:0' shape=(?, 1, 6, 3) dtype=float32>, <tf.Tensor 'conv-maxpool-4-u_4/concat:0' shape=(?, 1, 6, 3) dtype=float32>]\n",
      "DEBUG: h_pool_r -> Tensor(\"concat_9:0\", shape=(?, 1, 6, 6), dtype=float32)\n",
      "DEBUG: h_pool_flat_r -> Tensor(\"Reshape_9:0\", shape=(?, 6, 6), dtype=float32)\n",
      "DEBUG: h_features -> Tensor(\"dropout_4/concat:0\", shape=(?, 7, 6), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ac1040d65eac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_u_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_r_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/tensor/notebooks/liushuaiyi/cnn4aqqu/train_cnn.py\u001b[0m in \u001b[0;36mtrain_cnn\u001b[1;34m(x_u_i, x_r_i, y, max_len, U, config)\u001b[0m\n\u001b[0;32m     41\u001b[0m                   \u001b[0mnum_filters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_filters\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m                   \u001b[0mdropout_keep_prob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dropout_keep_prob\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m                   embeddings_trainable=config[\"embeddings_trainable\"])\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mtotal_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"total_iter\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/tensor/notebooks/liushuaiyi/cnn4aqqu/sent_cnn.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sequence_length, num_classes, init_embeddings, filter_sizes, num_filters, dropout_keep_prob, embeddings_trainable)\u001b[0m\n\u001b[0;32m    148\u001b[0m             self.h_features_dropped = tf.nn.dropout(self.h_features, \n\u001b[0;32m    149\u001b[0m                                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_keep_prob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                                                     noise_shape=[None, 1, num_filters_total])\n\u001b[0m\u001b[0;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_dropped_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_features_dropped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_dropped_r\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh_features_dropped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.pyc\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(x, keep_prob, noise_shape, seed, name)\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[0mrandom_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m     random_tensor += random_ops.random_uniform(\n\u001b[1;32m--> 677\u001b[1;33m         noise_shape, seed=seed, dtype=x.dtype)\n\u001b[0m\u001b[0;32m    678\u001b[0m     \u001b[1;31m# 0. if [keep_prob, 1.0) and 1. if [1.0, 1.0 + keep_prob)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m     \u001b[0mbinary_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/random_ops.pyc\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"random_uniform\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ShapeTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m     \u001b[0mminval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"min\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"max\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/random_ops.pyc\u001b[0m in \u001b[0;36m_ShapeTensor\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m     43\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconversion_func\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfuncs_at_priority\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m           raise RuntimeError(\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.pyc\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    177\u001b[0m                                          as_ref=False):\n\u001b[0;32m    178\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/constant_op.pyc\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    160\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m--> 162\u001b[1;33m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape))\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_util.pyc\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape)\u001b[0m\n\u001b[0;32m    388\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnumpy_dtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[0mproto_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FlattenToStrings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m     \u001b[0mtensor_proto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/compat.pyc\u001b[0m in \u001b[0;36mas_bytes\u001b[1;34m(bytes_or_text)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expected binary or unicode string, got %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got None"
     ]
    }
   ],
   "source": [
    "train_cnn.train_cnn(x_u_i, x_r_i, y, max_len, U, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
