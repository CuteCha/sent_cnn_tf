{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import data_helpers\n",
    "from sent_cnn import SentCNN\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_u, x_r, y, max_len = data_helpers.get_training_examples_for_softmax(\"./data/webquestions.examples.train.e2e.top10.filter.patrel.sid.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad = lambda x: data_helpers.pad_sentences(x, max_len)\n",
    "pad_lst = lambda x: map(pad, x)\n",
    "x_u = map(pad, x_u)\n",
    "x_r = map(pad_lst, x_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens, U = data_helpers.get_pretrained_wordvec_from_file(\"./data/word_representations/glove.6B.100d.txt\", (400000, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dctize = lambda word: tokens[word] if tokens.has_key(word) else tokens[\"pad\"]\n",
    "dctizes = lambda words: map(dctize, words)\n",
    "dctizess = lambda wordss: map(dctizes, wordss)\n",
    "x_u_i = np.array(map(dctizes, x_u))\n",
    "x_r_i = np.array(map(dctizess, x_r))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn = SentCNN(sequence_length=max_len, \n",
    "              num_classes=6, \n",
    "              init_embeddings=U, \n",
    "              filter_sizes=[3, 4], \n",
    "              num_filters=3,\n",
    "              embeddings_trainable=False)\n",
    "batch_size = 500\n",
    "global_step = tf.Variable(0, name=\"global_step\", trainable=True)\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    for _ in range(400000):\n",
    "        indices = np.random.choice(len(x_u_i), batch_size)\n",
    "        x_u_batch = x_u_i[indices]\n",
    "        x_r_batch = x_r_i[indices]\n",
    "        y_batch = y[indices]\n",
    "        feed_dict = {\n",
    "            cnn.input_x_u: x_u_batch, \n",
    "            cnn.input_x_r: x_r_batch,\n",
    "            cnn.input_y: y_batch\n",
    "        }\n",
    "    \n",
    "        _, step, loss, accuracy, cosine, pred = sess.run(\n",
    "            [train_op, global_step, cnn.loss, cnn.accuracy, cnn.cosine, cnn.predictions], feed_dict)\n",
    "        time_str = datetime.datetime.now().isoformat()\n",
    "        if step % 50 == 0:\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))  \n",
    "            print pred[:5], y_batch[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.shape(x_r_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import data_helpers\n",
    "import train_cnn\n",
    "from sent_cnn import SentCNN\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_u_i, x_r_i, y, max_len, U = train_cnn.load_data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: embedded_u -> Tensor(\"embedding_1/embedding_lookup:0\", shape=(?, 22, 100), dtype=float32)\n",
      "DEBUG: embedded_r -> Tensor(\"embedding_1/embedding_lookup_1:0\", shape=(?, 6, 22, 100), dtype=float32)\n",
      "DEBUG: embedded_u_expanded -> Tensor(\"embedding_1/ExpandDims:0\", shape=(?, 22, 100, 1), dtype=float32)\n",
      "DEBUG: embedded_r_expanded -> Tensor(\"embedding_1/ExpandDims_1:0\", shape=(?, 6, 22, 100, 1), dtype=float32)\n",
      "DEBUG: pooled_outputs_u -> [<tf.Tensor 'conv-maxpool-3-u_1/pool-u:0' shape=(?, 1, 1, 3) dtype=float32>, <tf.Tensor 'conv-maxpool-4-u_1/pool-u:0' shape=(?, 1, 1, 3) dtype=float32>]\n",
      "DEBUG: h_pool_u -> Tensor(\"concat_2:0\", shape=(?, 1, 1, 6), dtype=float32)\n",
      "DEBUG: h_pool_flat_u -> Tensor(\"Reshape_2:0\", shape=(?, 1, 6), dtype=float32)\n",
      "DEBUG: pooled_outputs_r -> [<tf.Tensor 'conv-maxpool-3-u_1/concat:0' shape=(?, 1, 6, 3) dtype=float32>, <tf.Tensor 'conv-maxpool-4-u_1/concat:0' shape=(?, 1, 6, 3) dtype=float32>]\n",
      "DEBUG: h_pool_r -> Tensor(\"concat_3:0\", shape=(?, 1, 6, 6), dtype=float32)\n",
      "DEBUG: h_pool_flat_r -> Tensor(\"Reshape_3:0\", shape=(?, 6, 6), dtype=float32)\n",
      "DEBUG: dot -> Tensor(\"cosine_layer_1/Sum:0\", shape=(?, 6), dtype=float32)\n",
      "DEBUG: sqrt_u -> Tensor(\"cosine_layer_1/Sqrt:0\", shape=(?, 1), dtype=float32)\n",
      "DEBUG: sqrt_r -> Tensor(\"cosine_layer_1/Sqrt_1:0\", shape=(?, 6), dtype=float32)\n",
      "DEBUG: cosine -> Tensor(\"cosine_layer_1/div:0\", shape=(?, 6), dtype=float32)\n",
      "DEBUG: predictions -> Tensor(\"cosine_layer_1/predictions:0\", shape=(?,), dtype=int64)\n",
      "2016-05-12T07:47:11.692709: step 50, train loss 1.11767, train acc 0.648, dev loss 1.08094, dev acc 0.66\n",
      "[5 3 4 0 1] [5 2 0 3 1]\n",
      "2016-05-12T07:47:20.896711: step 100, train loss 0.808309, train acc 0.718, dev loss 0.804975, dev acc 0.748\n",
      "[5 2 5 5 3] [4 3 5 5 3]\n",
      "2016-05-12T07:47:30.065178: step 150, train loss 0.682706, train acc 0.764, dev loss 0.696417, dev acc 0.788\n",
      "[4 3 4 5 0] [4 3 4 5 0]\n",
      "2016-05-12T07:47:39.240473: step 200, train loss 0.55599, train acc 0.804, dev loss 0.62029, dev acc 0.814\n",
      "[4 0 4 3 0] [4 0 4 3 0]\n",
      "2016-05-12T07:47:48.414495: step 250, train loss 0.541611, train acc 0.822, dev loss 0.571625, dev acc 0.82\n",
      "[2 0 2 0 4] [2 0 2 0 4]\n",
      "2016-05-12T07:47:57.522136: step 300, train loss 0.429433, train acc 0.848, dev loss 0.541092, dev acc 0.822\n",
      "[5 4 2 4 1] [5 4 2 4 1]\n",
      "2016-05-12T07:48:06.669091: step 350, train loss 0.348374, train acc 0.856, dev loss 0.519049, dev acc 0.824\n",
      "[5 3 1 3 4] [5 3 1 3 4]\n",
      "2016-05-12T07:48:15.810077: step 400, train loss 0.430039, train acc 0.856, dev loss 0.503882, dev acc 0.832\n",
      "[0 5 3 2 2] [0 5 2 2 4]\n",
      "2016-05-12T07:48:24.935660: step 450, train loss 0.328792, train acc 0.896, dev loss 0.508265, dev acc 0.826\n",
      "[0 2 2 5 3] [0 2 2 5 5]\n",
      "2016-05-12T07:48:34.063229: step 500, train loss 0.383205, train acc 0.858, dev loss 0.493881, dev acc 0.826\n",
      "[2 0 5 5 4] [2 0 4 5 4]\n",
      "2016-05-12T07:48:43.192710: step 550, train loss 0.348547, train acc 0.87, dev loss 0.495785, dev acc 0.832\n",
      "[5 5 1 4 5] [5 5 1 4 4]\n",
      "2016-05-12T07:48:52.320745: step 600, train loss 0.346821, train acc 0.89, dev loss 0.505705, dev acc 0.816\n",
      "[5 4 4 1 0] [5 4 3 1 0]\n",
      "2016-05-12T07:49:01.512038: step 650, train loss 0.303503, train acc 0.894, dev loss 0.478555, dev acc 0.828\n",
      "[0 4 0 1 0] [0 4 0 1 0]\n",
      "2016-05-12T07:49:10.650963: step 700, train loss 0.324613, train acc 0.88, dev loss 0.482605, dev acc 0.844\n",
      "[0 4 5 0 5] [0 4 5 3 5]\n",
      "2016-05-12T07:49:19.822534: step 750, train loss 0.275777, train acc 0.902, dev loss 0.490498, dev acc 0.83\n",
      "[2 2 0 5 5] [2 2 0 5 5]\n",
      "2016-05-12T07:49:28.966652: step 800, train loss 0.263021, train acc 0.914, dev loss 0.508208, dev acc 0.834\n",
      "[1 1 5 4 2] [1 1 5 4 2]\n",
      "2016-05-12T07:49:38.054543: step 850, train loss 0.260798, train acc 0.902, dev loss 0.494781, dev acc 0.846\n",
      "[5 1 1 5 0] [5 1 4 0 5]\n",
      "2016-05-12T07:49:47.132713: step 900, train loss 0.224563, train acc 0.908, dev loss 0.496513, dev acc 0.842\n",
      "[2 1 0 4 1] [2 1 0 4 1]\n",
      "2016-05-12T07:49:56.147186: step 950, train loss 0.229793, train acc 0.904, dev loss 0.508028, dev acc 0.844\n",
      "[1 0 4 1 3] [1 0 4 1 3]\n",
      "2016-05-12T07:50:05.184214: step 1000, train loss 0.224659, train acc 0.934, dev loss 0.503829, dev acc 0.846\n",
      "[0 5 3 0 5] [0 4 3 0 5]\n",
      "2016-05-12T07:50:14.255502: step 1050, train loss 0.227705, train acc 0.902, dev loss 0.525283, dev acc 0.84\n",
      "[2 1 2 3 0] [2 0 2 3 0]\n",
      "2016-05-12T07:50:23.292992: step 1100, train loss 0.208864, train acc 0.912, dev loss 0.554385, dev acc 0.844\n",
      "[5 5 2 5 1] [5 5 2 5 2]\n",
      "2016-05-12T07:50:32.345348: step 1150, train loss 0.219573, train acc 0.904, dev loss 0.540221, dev acc 0.842\n",
      "[4 1 2 5 0] [4 1 2 5 0]\n",
      "2016-05-12T07:50:41.349991: step 1200, train loss 0.227545, train acc 0.906, dev loss 0.568428, dev acc 0.834\n",
      "[0 2 4 1 0] [0 2 4 1 0]\n",
      "2016-05-12T07:50:50.347909: step 1250, train loss 0.252971, train acc 0.91, dev loss 0.577144, dev acc 0.836\n",
      "[5 4 0 5 5] [5 4 0 5 5]\n",
      "2016-05-12T07:50:59.342955: step 1300, train loss 0.205374, train acc 0.914, dev loss 0.55248, dev acc 0.86\n",
      "[4 0 3 3 2] [4 0 3 3 2]\n",
      "2016-05-12T07:51:08.358915: step 1350, train loss 0.207128, train acc 0.934, dev loss 0.570006, dev acc 0.824\n",
      "[3 1 2 5 0] [3 1 2 5 3]\n",
      "2016-05-12T07:51:17.389433: step 1400, train loss 0.172954, train acc 0.932, dev loss 0.572809, dev acc 0.854\n",
      "[5 3 5 0 5] [5 3 5 0 5]\n",
      "2016-05-12T07:51:26.410876: step 1450, train loss 0.19854, train acc 0.914, dev loss 0.5732, dev acc 0.864\n",
      "[3 0 3 1 3] [3 0 3 1 3]\n",
      "2016-05-12T07:51:35.413245: step 1500, train loss 0.174534, train acc 0.934, dev loss 0.611176, dev acc 0.838\n",
      "[0 5 0 5 4] [0 5 0 5 4]\n",
      "2016-05-12T07:51:44.417319: step 1550, train loss 0.147391, train acc 0.93, dev loss 0.622016, dev acc 0.832\n",
      "[5 5 4 2 5] [5 3 4 2 5]\n",
      "2016-05-12T07:51:53.392673: step 1600, train loss 0.16711, train acc 0.934, dev loss 0.600497, dev acc 0.848\n",
      "[2 3 4 4 2] [2 3 4 4 2]\n",
      "2016-05-12T07:52:02.365997: step 1650, train loss 0.186895, train acc 0.932, dev loss 0.622281, dev acc 0.844\n",
      "[1 5 2 4 3] [2 4 2 0 3]\n",
      "2016-05-12T07:52:11.376020: step 1700, train loss 0.147082, train acc 0.924, dev loss 0.64663, dev acc 0.838\n",
      "[5 0 1 4 0] [5 0 1 4 0]\n",
      "2016-05-12T07:52:20.403220: step 1750, train loss 0.138945, train acc 0.944, dev loss 0.65785, dev acc 0.838\n",
      "[2 0 1 4 5] [2 0 3 4 5]\n",
      "2016-05-12T07:52:29.372519: step 1800, train loss 0.174493, train acc 0.92, dev loss 0.68229, dev acc 0.824\n",
      "[3 4 4 0 1] [3 4 4 0 1]\n",
      "2016-05-12T07:52:38.354021: step 1850, train loss 0.188214, train acc 0.934, dev loss 0.684512, dev acc 0.838\n",
      "[2 2 5 5 1] [2 2 5 5 2]\n",
      "2016-05-12T07:52:47.393324: step 1900, train loss 0.105339, train acc 0.952, dev loss 0.702067, dev acc 0.844\n",
      "[0 1 1 3 1] [0 1 1 3 1]\n",
      "2016-05-12T07:52:56.350798: step 1950, train loss 0.156098, train acc 0.932, dev loss 0.698357, dev acc 0.838\n",
      "[5 2 2 5 1] [5 2 2 5 1]\n",
      "2016-05-12T07:53:05.369868: step 2000, train loss 0.150829, train acc 0.926, dev loss 0.724563, dev acc 0.844\n",
      "[5 1 1 0 3] [5 1 1 0 3]\n",
      "2016-05-12T07:53:14.374913: step 2050, train loss 0.0962981, train acc 0.956, dev loss 0.73641, dev acc 0.85\n",
      "[5 5 4 3 0] [5 5 4 3 4]\n",
      "2016-05-12T07:53:23.369618: step 2100, train loss 0.150962, train acc 0.934, dev loss 0.758563, dev acc 0.836\n",
      "[1 2 0 2 2] [1 2 0 2 2]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ac1040d65eac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_u_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_r_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mU\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/opt/tensor/notebooks/liushuaiyi/cnn4aqqu/train_cnn.py\u001b[0m in \u001b[0;36mtrain_cnn\u001b[1;34m(x_u_i, x_r_i, y, max_len, U, config)\u001b[0m\n\u001b[0;32m     71\u001b[0m             }\n\u001b[0;32m     72\u001b[0m             _, step, loss, accuracy, cosine, pred = sess.run(\n\u001b[1;32m---> 73\u001b[1;33m                 [train_op, global_step, cnn.loss, cnn.accuracy, cnn.cosine, cnn.predictions], feed_dict)\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[0mtime_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misoformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m50\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 340\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    341\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 564\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       \u001b[1;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 637\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    638\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    642\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0merror_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m--> 628\u001b[1;33m             session, None, feed_dict, fetch_list, target_list, None)\n\u001b[0m\u001b[0;32m    629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_cnn.train_cnn(x_u_i, x_r_i, y, max_len, U, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
